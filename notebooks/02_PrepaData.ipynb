{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106a1053",
   "metadata": {},
   "source": [
    "# PrepaData: Feature Engineering and Metrics Computation\n",
    "\n",
    "## Overview\n",
    "\n",
    "The PrepaData microservice processes normalized data from the LMS connector to compute aggregated metrics at the **student-module-presentation** level. These metrics serve as features for downstream tasks:\n",
    "\n",
    "- **Student Profiling**: Clustering students based on learning patterns\n",
    "- **Path Prediction**: Predicting student success using XGBoost\n",
    "- **Recommendation System**: Building personalized learning paths\n",
    "\n",
    "## What Metrics Are Computed?\n",
    "\n",
    "For each combination of `(student_id, code_module, code_presentation)`, we compute:\n",
    "\n",
    "1. **avg_score**: Weighted average of assessment scores\n",
    "2. **completion_rate**: Ratio of completed assessments to total assessments (0.0 to 1.0)\n",
    "3. **total_clicks**: Total number of VLE (Virtual Learning Environment) clicks\n",
    "4. **active_days**: Number of unique days with recorded activity\n",
    "5. **final_result**: Final course result (Pass/Fail/Withdrawn/Distinction)\n",
    "\n",
    "## Pipeline Position\n",
    "\n",
    "```\n",
    "01_LMSConnector → 02_PrepaData → 03_StudentProfiler → 04_PathPredictor → 05_RecoBuilder\n",
    "     (Raw Data)    (Features)      (Clustering)        (ML Model)        (Recommendations)\n",
    "```\n",
    "\n",
    "## Input Data\n",
    "\n",
    "This notebook expects normalized CSV files in `data/processed/`:\n",
    "- `student_info_normalized.csv`\n",
    "- `registrations_normalized.csv`\n",
    "- `assessments_normalized.csv`\n",
    "- `student_assessment_normalized.csv`\n",
    "- `student_vle_normalized.csv`\n",
    "- `vle_info_normalized.csv`\n",
    "- `courses_normalized.csv`\n",
    "\n",
    "## Output\n",
    "\n",
    "Generates `data/processed/student_module_metrics.csv` with aggregated metrics ready for ML pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "833f6ae4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Import the PrepaData pipeline\n",
    "from libs.prepa_data import run_prepa_data_pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a11ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete PrepaData pipeline\n",
    "metrics_df = run_prepa_data_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "print(\"First 10 rows of computed metrics:\")\n",
    "print(metrics_df.head(10))\n",
    "print(f\"\\nDataFrame shape: {metrics_df.shape}\")\n",
    "print(f\"\\nColumn names: {list(metrics_df.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(metrics_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(metrics_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d70e24",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Let's explore the distributions of key metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution of average scores\n",
    "axes[0, 0].hist(metrics_df['avg_score'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Average Scores', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Average Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribution of completion rates\n",
    "axes[0, 1].hist(metrics_df['completion_rate'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Distribution of Completion Rates', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Completion Rate')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribution of total clicks (log scale for better visualization)\n",
    "axes[1, 0].hist(metrics_df[metrics_df['total_clicks'] > 0]['total_clicks'], \n",
    "                bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Distribution of Total Clicks (Non-zero)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Total Clicks')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distribution of active days\n",
    "axes[1, 1].hist(metrics_df['active_days'], bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[1, 1].set_title('Distribution of Active Days', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Active Days')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae77f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap of numeric metrics\n",
    "numeric_cols = ['avg_score', 'completion_rate', 'total_clicks', 'active_days']\n",
    "correlation_matrix = metrics_df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Student-Module Metrics', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final result distribution\n",
    "if 'final_result' in metrics_df.columns:\n",
    "    result_counts = metrics_df['final_result'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    result_counts.plot(kind='bar', color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    plt.title('Distribution of Final Results', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Final Result')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFinal Result Distribution:\")\n",
    "    print(result_counts)\n",
    "    print(f\"\\nPercentages:\")\n",
    "    print((result_counts / len(metrics_df) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the output file path\n",
    "from pathlib import Path\n",
    "from libs.utils import get_data_paths\n",
    "\n",
    "_, processed_dir = get_data_paths()\n",
    "output_file = processed_dir / \"student_module_metrics.csv\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OUTPUT FILE LOCATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n✓ Generated file: {output_file}\")\n",
    "print(f\"✓ File exists: {output_file.exists()}\")\n",
    "if output_file.exists():\n",
    "    print(f\"✓ File size: {output_file.stat().st_size / 1024:.2f} KB\")\n",
    "    print(f\"✓ Total rows: {len(metrics_df)}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
